{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "_zy8hc9XgB2F"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # For 3-channel RGB images\n",
        "])\n",
        "\n",
        "# Load CIFAR-10\n",
        "dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n"
      ],
      "metadata": {
        "id": "QF5leyjfgFO9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim=100, img_channels=3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            # Start: 100-dims -> 4x4x512 feature map\n",
        "            nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            # 4x4x512 -> 8x8x256\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            # 8x8x256 -> 16x16x128\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            # 16x16x128 -> 32x32x3\n",
        "            nn.ConvTranspose2d(128, img_channels, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = z.view(z.size(0), z.size(1), 1, 1)\n",
        "        img = self.model(z)\n",
        "        return img\n",
        "\n",
        "# Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, img_channels=3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            # 32x32x3 -> 16x16x128\n",
        "            nn.Conv2d(img_channels, 128, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            # 16x16x128 -> 8x8x256\n",
        "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            # 8x8x256 -> 4x4x512\n",
        "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            # 4x4x512 -> 1x1x1\n",
        "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
        "            nn.Flatten(),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        output = self.model(img)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "VQL7Rr2MgKVg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 100\n",
        "img_channels = 3\n",
        "G = Generator(latent_dim, img_channels).to(device)\n",
        "D = Discriminator(img_channels).to(device)\n",
        "\n",
        "# Loss and optimizers\n",
        "criterion = nn.BCELoss()\n",
        "lr = 0.0002\n",
        "opt_G = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "opt_D = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n"
      ],
      "metadata": {
        "id": "7Y1--vkngSzc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('output', exist_ok=True)\n",
        "fixed_noise = torch.randn(16, latent_dim, device=device)\n",
        "\n",
        "n_epochs = 50\n",
        "for epoch in range(n_epochs):\n",
        "    for i, (real_imgs, _) in enumerate(dataloader):\n",
        "        real_imgs = real_imgs.to(device)\n",
        "        batch_size = real_imgs.size(0)\n",
        "\n",
        "        # Discriminator: Maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        D.zero_grad()\n",
        "        label_real = torch.ones(batch_size, 1, device=device)\n",
        "        output_real = D(real_imgs)\n",
        "        loss_D_real = criterion(output_real, label_real)\n",
        "\n",
        "        noise = torch.randn(batch_size, latent_dim, device=device)\n",
        "        fake_imgs = G(noise)\n",
        "        label_fake = torch.zeros(batch_size, 1, device=device)\n",
        "        output_fake = D(fake_imgs.detach())\n",
        "        loss_D_fake = criterion(output_fake, label_fake)\n",
        "\n",
        "        loss_D = loss_D_real + loss_D_fake\n",
        "        loss_D.backward()\n",
        "        opt_D.step()\n",
        "\n",
        "        # Generator: Minimize log(1 - D(G(z))) <=> Maximize log(D(G(z)))\n",
        "        G.zero_grad()\n",
        "        label_real.fill_(1)  # Trick generator to think its doing better, targets are \"1\"\n",
        "        output_fake = D(fake_imgs)\n",
        "        loss_G = criterion(output_fake, label_real)\n",
        "        loss_G.backward()\n",
        "        opt_G.step()\n",
        "\n",
        "    # Save generated images and print progress\n",
        "    if epoch % 5 == 0:\n",
        "        with torch.no_grad():\n",
        "            fake = G(fixed_noise).detach().cpu()\n",
        "            save_image(fake / 2 + 0.5, f'output/epoch_{epoch}.png', nrow=4)\n",
        "            print(f'Epoch {epoch} | Loss_D: {loss_D.item():.4f} | Loss_G: {loss_G.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Hm8sn3ygWgk",
        "outputId": "72356d5c-95a1-4a5b-8fad-a21bca894839"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Loss_D: 0.5934 | Loss_G: 5.1711\n",
            "Epoch 5 | Loss_D: 0.6531 | Loss_G: 1.9687\n",
            "Epoch 10 | Loss_D: 0.6235 | Loss_G: 3.4140\n",
            "Epoch 15 | Loss_D: 0.2120 | Loss_G: 2.8819\n",
            "Epoch 20 | Loss_D: 0.1533 | Loss_G: 4.5150\n",
            "Epoch 25 | Loss_D: 0.0867 | Loss_G: 3.7201\n",
            "Epoch 30 | Loss_D: 0.1291 | Loss_G: 3.9520\n",
            "Epoch 35 | Loss_D: 0.3536 | Loss_G: 5.9168\n",
            "Epoch 40 | Loss_D: 0.1392 | Loss_G: 4.2727\n",
            "Epoch 45 | Loss_D: 0.1662 | Loss_G: 5.1184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xX5X1VdjXY2",
        "outputId": "ce3e1128-ea8c-4831-c1e9-5a73929e2cc1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    }
  ]
}